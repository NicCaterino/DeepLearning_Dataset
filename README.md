This project investigates the application of deep neural networks for text compression, focusing on
character-to-symbol sequence translation. We propose a survey on methods based on converting
human-readable text into a format compatible with existing decompression tools like ZIP, bypassing
the need for intermediate representations. Several model were tested (Dense, CNN, RNN, custom) by
training on a diverse dataset of text documents, including BBC articles and American high school
eleventh-grade textbooks. The models are trained to produce outputs resembling the corresponding
ZIP files generated by the software 7-Zip. We evaluate the models using two metrics: Levenshtein
distance and a custom "unzip metric" that reflects successful decompression
